{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import losses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:\\THANH\\RESEARCH\\LE01\\Malware_subset.csv')\n",
    "y = data['Label']\n",
    "features = ['Label',' Protocol',' Bwd Packet Length Min',' Down/Up Ratio',' Min Packet Length']\n",
    "X = data.drop(columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  2  2 ... 10 10 10]\n",
      "(834695,)\n"
     ]
    }
   ],
   "source": [
    "trans=QuantileTransformer()\n",
    "test=trans.fit_transform(X)\n",
    "transformer = MinMaxScaler()\n",
    "X=transformer.fit_transform(test)\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(data['Label'])\n",
    "print(y)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667756, 76)\n",
      "(667756,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 10ms/step - accuracy: 0.5210 - loss: 1.7160 - val_accuracy: 0.5509 - val_loss: 1.6079\n",
      "Epoch 2/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 15ms/step - accuracy: 0.5517 - loss: 1.5944 - val_accuracy: 0.5540 - val_loss: 1.5764\n",
      "Epoch 3/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10ms/step - accuracy: 0.5564 - loss: 1.5650 - val_accuracy: 0.5565 - val_loss: 1.5588\n",
      "Epoch 4/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 9ms/step - accuracy: 0.5585 - loss: 1.5496 - val_accuracy: 0.5606 - val_loss: 1.5438\n",
      "Epoch 5/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9ms/step - accuracy: 0.5610 - loss: 1.5372 - val_accuracy: 0.5610 - val_loss: 1.5380\n",
      "Epoch 6/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9ms/step - accuracy: 0.5603 - loss: 1.5331 - val_accuracy: 0.5618 - val_loss: 1.5357\n",
      "Epoch 7/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 9ms/step - accuracy: 0.5618 - loss: 1.5263 - val_accuracy: 0.5618 - val_loss: 1.5313\n",
      "Epoch 8/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9ms/step - accuracy: 0.5623 - loss: 1.5215 - val_accuracy: 0.5616 - val_loss: 1.5311\n",
      "Epoch 9/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9ms/step - accuracy: 0.5626 - loss: 1.5189 - val_accuracy: 0.5641 - val_loss: 1.5204\n",
      "Epoch 10/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 9ms/step - accuracy: 0.5642 - loss: 1.5097 - val_accuracy: 0.5631 - val_loss: 1.5197\n",
      "Epoch 11/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 10ms/step - accuracy: 0.5631 - loss: 1.5124 - val_accuracy: 0.5639 - val_loss: 1.5198\n",
      "Epoch 12/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 9ms/step - accuracy: 0.5639 - loss: 1.5084 - val_accuracy: 0.5637 - val_loss: 1.5145\n",
      "Epoch 13/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 9ms/step - accuracy: 0.5634 - loss: 1.5073 - val_accuracy: 0.5638 - val_loss: 1.5189\n",
      "Epoch 14/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9ms/step - accuracy: 0.5646 - loss: 1.5037 - val_accuracy: 0.5648 - val_loss: 1.5131\n",
      "Epoch 15/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 9ms/step - accuracy: 0.5653 - loss: 1.5005 - val_accuracy: 0.5641 - val_loss: 1.5152\n",
      "Epoch 16/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.5655 - loss: 1.4993 - val_accuracy: 0.5646 - val_loss: 1.5087\n",
      "Epoch 17/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 10ms/step - accuracy: 0.5655 - loss: 1.4983 - val_accuracy: 0.5647 - val_loss: 1.5065\n",
      "Epoch 18/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 10ms/step - accuracy: 0.5649 - loss: 1.4974 - val_accuracy: 0.5660 - val_loss: 1.5037\n",
      "Epoch 19/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 9ms/step - accuracy: 0.5653 - loss: 1.4952 - val_accuracy: 0.5658 - val_loss: 1.5039\n",
      "Epoch 20/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 9ms/step - accuracy: 0.5656 - loss: 1.4946 - val_accuracy: 0.5655 - val_loss: 1.5055\n",
      "Epoch 21/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 9ms/step - accuracy: 0.5665 - loss: 1.4920 - val_accuracy: 0.5660 - val_loss: 1.5053\n",
      "Epoch 22/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.5674 - loss: 1.4897 - val_accuracy: 0.5660 - val_loss: 1.5034\n",
      "Epoch 23/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10ms/step - accuracy: 0.5663 - loss: 1.4906 - val_accuracy: 0.5655 - val_loss: 1.5011\n",
      "Epoch 24/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 76ms/step - accuracy: 0.5668 - loss: 1.4890 - val_accuracy: 0.5645 - val_loss: 1.5039\n",
      "Epoch 25/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4014s\u001b[0m 252ms/step - accuracy: 0.5671 - loss: 1.4854 - val_accuracy: 0.5663 - val_loss: 1.4980\n",
      "Epoch 26/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9ms/step - accuracy: 0.5660 - loss: 1.4886 - val_accuracy: 0.5657 - val_loss: 1.5022\n",
      "Epoch 27/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9ms/step - accuracy: 0.5673 - loss: 1.4845 - val_accuracy: 0.5661 - val_loss: 1.5011\n",
      "Epoch 28/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9ms/step - accuracy: 0.5666 - loss: 1.4869 - val_accuracy: 0.5659 - val_loss: 1.5013\n",
      "Epoch 29/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9ms/step - accuracy: 0.5671 - loss: 1.4844 - val_accuracy: 0.5666 - val_loss: 1.4978\n",
      "Epoch 30/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 22ms/step - accuracy: 0.5686 - loss: 1.4803 - val_accuracy: 0.5667 - val_loss: 1.4959\n",
      "Epoch 31/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 33ms/step - accuracy: 0.5674 - loss: 1.4831 - val_accuracy: 0.5659 - val_loss: 1.4996\n",
      "Epoch 32/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 32ms/step - accuracy: 0.5672 - loss: 1.4833 - val_accuracy: 0.5663 - val_loss: 1.4965\n",
      "Epoch 33/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 26ms/step - accuracy: 0.5667 - loss: 1.4835 - val_accuracy: 0.5661 - val_loss: 1.5007\n",
      "Epoch 34/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 23ms/step - accuracy: 0.5671 - loss: 1.4828 - val_accuracy: 0.5667 - val_loss: 1.4950\n",
      "Epoch 35/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 25ms/step - accuracy: 0.5679 - loss: 1.4801 - val_accuracy: 0.5668 - val_loss: 1.5016\n",
      "Epoch 36/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 26ms/step - accuracy: 0.5674 - loss: 1.4814 - val_accuracy: 0.5665 - val_loss: 1.5009\n",
      "Epoch 37/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 27ms/step - accuracy: 0.5679 - loss: 1.4795 - val_accuracy: 0.5668 - val_loss: 1.4973\n",
      "Epoch 38/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 27ms/step - accuracy: 0.5682 - loss: 1.4785 - val_accuracy: 0.5670 - val_loss: 1.4969\n",
      "Epoch 39/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 23ms/step - accuracy: 0.5677 - loss: 1.4792 - val_accuracy: 0.5666 - val_loss: 1.4953\n",
      "Epoch 40/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 25ms/step - accuracy: 0.5680 - loss: 1.4769 - val_accuracy: 0.5659 - val_loss: 1.4982\n",
      "Epoch 41/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 32ms/step - accuracy: 0.5686 - loss: 1.4777 - val_accuracy: 0.5667 - val_loss: 1.4964\n",
      "Epoch 42/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 34ms/step - accuracy: 0.5681 - loss: 1.4778 - val_accuracy: 0.5669 - val_loss: 1.4953\n",
      "Epoch 43/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1082s\u001b[0m 68ms/step - accuracy: 0.5674 - loss: 1.4792 - val_accuracy: 0.5666 - val_loss: 1.4975\n",
      "Epoch 44/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 36ms/step - accuracy: 0.5680 - loss: 1.4769 - val_accuracy: 0.5665 - val_loss: 1.4960\n",
      "Epoch 45/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 24ms/step - accuracy: 0.5678 - loss: 1.4766 - val_accuracy: 0.5664 - val_loss: 1.5030\n",
      "Epoch 46/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 30ms/step - accuracy: 0.5689 - loss: 1.4743 - val_accuracy: 0.5672 - val_loss: 1.4974\n",
      "Epoch 47/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 40ms/step - accuracy: 0.5684 - loss: 1.4750 - val_accuracy: 0.5666 - val_loss: 1.4970\n",
      "Epoch 48/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 45ms/step - accuracy: 0.5696 - loss: 1.4725 - val_accuracy: 0.5680 - val_loss: 1.4916\n",
      "Epoch 49/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 34ms/step - accuracy: 0.5689 - loss: 1.4722 - val_accuracy: 0.5662 - val_loss: 1.4950\n",
      "Epoch 50/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 35ms/step - accuracy: 0.5693 - loss: 1.4717 - val_accuracy: 0.5675 - val_loss: 1.4969\n",
      "Epoch 51/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 32ms/step - accuracy: 0.5682 - loss: 1.4739 - val_accuracy: 0.5677 - val_loss: 1.4923\n",
      "Epoch 52/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 34ms/step - accuracy: 0.5680 - loss: 1.4737 - val_accuracy: 0.5656 - val_loss: 1.5019\n",
      "Epoch 53/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 39ms/step - accuracy: 0.5695 - loss: 1.4721 - val_accuracy: 0.5663 - val_loss: 1.5008\n",
      "Epoch 54/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 39ms/step - accuracy: 0.5700 - loss: 1.4699 - val_accuracy: 0.5678 - val_loss: 1.4938\n",
      "Epoch 55/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 47ms/step - accuracy: 0.5696 - loss: 1.4704 - val_accuracy: 0.5669 - val_loss: 1.4935\n",
      "Epoch 56/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 43ms/step - accuracy: 0.5695 - loss: 1.4705 - val_accuracy: 0.5669 - val_loss: 1.4928\n",
      "Epoch 57/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 41ms/step - accuracy: 0.5699 - loss: 1.4692 - val_accuracy: 0.5670 - val_loss: 1.5000\n",
      "Epoch 58/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 31ms/step - accuracy: 0.5689 - loss: 1.4715 - val_accuracy: 0.5666 - val_loss: 1.4985\n",
      "Epoch 59/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1204s\u001b[0m 76ms/step - accuracy: 0.5687 - loss: 1.4709 - val_accuracy: 0.5672 - val_loss: 1.4944\n",
      "Epoch 60/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 11ms/step - accuracy: 0.5686 - loss: 1.4711 - val_accuracy: 0.5661 - val_loss: 1.4942\n",
      "Epoch 61/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 10ms/step - accuracy: 0.5696 - loss: 1.4711 - val_accuracy: 0.5669 - val_loss: 1.4939\n",
      "Epoch 62/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 10ms/step - accuracy: 0.5696 - loss: 1.4687 - val_accuracy: 0.5672 - val_loss: 1.4933\n",
      "Epoch 63/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 11ms/step - accuracy: 0.5703 - loss: 1.4679 - val_accuracy: 0.5676 - val_loss: 1.4963\n",
      "Epoch 64/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 11ms/step - accuracy: 0.5689 - loss: 1.4715 - val_accuracy: 0.5682 - val_loss: 1.5011\n",
      "Epoch 65/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.5689 - loss: 1.4718 - val_accuracy: 0.5674 - val_loss: 1.4933\n",
      "Epoch 66/100\n",
      "\u001b[1m15899/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 11ms/step - accuracy: 0.5694 - loss: 1.4700 - val_accuracy: 0.5671 - val_loss: 1.4958\n",
      "Epoch 67/100\n",
      "\u001b[1m10611/15899\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 26ms/step - accuracy: 0.5692 - loss: 1.4700"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)),    #Tạo feature maps\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),                                                                  #Giảm kích thước của feature maps\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),                                                                                  #Chuyển feature maps thành vector 1 chiều\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(11, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # Monitor validation loss\n",
    "                                patience=15,  # Stop training after 5 epochs with no improvement\n",
    "                                verbose=1)  # Print messages during training\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "history=model.fit(x_train, y_train, batch_size=42, epochs=100,  # Adjust epochs if needed\n",
    "          validation_data=(x_test, y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['train_loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,100)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5217/5217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.0594801e-02, 1.6050442e-01, 1.7226365e-01, ..., 1.5503424e-01,\n",
       "        8.5627720e-02, 4.9966592e-01],\n",
       "       [5.8814207e-09, 2.6172836e-05, 4.0901603e-05, ..., 2.5212095e-05,\n",
       "        9.8788213e-09, 4.0120690e-04],\n",
       "       [1.8614641e-04, 3.4489674e-03, 4.0559499e-03, ..., 3.0855425e-03,\n",
       "        3.0303380e-04, 6.2777000e-03],\n",
       "       ...,\n",
       "       [2.3080801e-27, 1.9118083e-28, 3.0800587e-26, ..., 1.5969386e-26,\n",
       "        1.9647465e-27, 1.3950024e-25],\n",
       "       [1.4591918e-10, 1.3136513e-06, 1.6735752e-06, ..., 1.2316287e-06,\n",
       "        1.9431254e-10, 2.9617347e-06],\n",
       "       [7.4499734e-03, 8.4036263e-03, 6.4409235e-03, ..., 7.9128342e-03,\n",
       "        1.0681178e-02, 1.4343543e-01]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predtrain=model.predict(x_train)\n",
    "predtest=model.predict(x_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
